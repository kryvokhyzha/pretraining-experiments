defaults:
  - _self_
  - hydra: default
  - model: gemma_3_270mb
  - tokenizer: auto

seed: 42

# Inference settings
prompts:
  - "2 + 2 = "
  - "The future of AI is"
  - "Колись давно у далекій-далекій"

# Generation parameters
generation:
  max_new_tokens: 128
  temperature: 0.7
  top_p: 0.9
  top_k: null
  do_sample: true
  num_return_sequences: 1
  repetition_penalty: 1.0
  use_cache: true
